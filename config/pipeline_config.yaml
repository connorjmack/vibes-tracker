ingest:
  videos_per_channel: 30
  cache_channel_ids: true
  channel_id_cache_path: "data/channel_ids.json"

analysis:
  model: "llama3.1:latest"  # Ollama model (alternatives: mistral, mixtral, qwen2.5, llama3.2, etc.)
  max_tokens: 64000
  enable_caching: true
  cache_dir: "data/cache"

visualization:
  output_dir: "figures"
  wordcloud_width: 1200
  wordcloud_height: 800
  custom_stopwords:
    - "video"
    - "podcast"
    - "episode"
    - "watch"
    - "new"
    - "today"
    - "full"
    - "live"

rate_limiting:
  # YouTube Data API settings
  youtube_api:
    enabled: true
    min_delay_seconds: 1.0          # Minimum delay between requests (prevents IP blocking)
    max_delay_seconds: 60.0         # Maximum backoff delay
    max_retries: 5                  # Maximum retry attempts
    backoff_multiplier: 2.0         # Exponential backoff multiplier (2^n)
    requests_per_second: 0.5        # Token bucket: max 1 request per 2 seconds
    burst_size: 3                   # Allow short bursts of 3 requests

  # Transcript API settings (web scraping)
  transcript_api:
    enabled: true
    min_delay_seconds: 0.5          # Faster for free API (no official quota)
    max_delay_seconds: 5.0          # Conservative max to prevent IP blocking
    delay_jitter: 0.3               # Random variance (Â±30%)
    max_retries: 3                  # Fewer retries for web scraping

  # Batch operation settings
  batch_operations:
    delay_between_batches: 2.0      # Delay after processing each batch
    max_parallel_workers: 5         # Reduce thread pool to prevent request spikes

paths:
  data_dir: "data"
  config_dir: "config"
  cluster_config: "config/clusters.json"
  cluster_data: "data/cluster_data.csv"
  analyzed_data: "data/analyzed_data.csv"
  logs_dir: "logs"
